import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import os
import csv
import re
import uuid
import time
import json

load_dotenv()

api_url = os.getenv("CLOVA_OCR_API_URL")
secret_key = os.getenv("CLOVA_OCR_SECRET_KEY")

# ê´‘ê³ ì„± í‚¤ì›Œë“œ ì…‹
promotional_text_set = {
    'ì§€ì›ë°›ê³ ', 'ì§€ì›ë°›ì•„', 'ì§€ì›ë°›ì•˜', 'ì§€ì›ë°›ì„ìˆ˜', 'ì§€ì›ì„ë°›ì€', 'ì§€ì›ì„ë°›ì•„', 'ì§€ì›ì„ë°›ê³ ', 'ì§€ì›ì„ë°›ì•˜',
    'ì œê³µë°›ê³ ', 'ì œê³µë°›ì•„', 'ì œê³µì„ë°›ì€', 'ì œê³µì„ë°›ì•„', 'ì œê³µì„ë°›ê³ ', 'ì œê³µì„ë°›ì•˜', 'ì œê³µë°›ì„ìˆ˜', 'ì œê³µë°›ì•˜',
    'ì„œí¬í„°ì¦ˆ', 'íŒŒíŠ¸ë„ˆìŠ¤', 'ì†Œì •ì˜', 'ìˆ˜ìˆ˜ë£Œ', 'ê³ ë£Œ', 'í˜‘ì°¬', 'ëŒ€ê°€', 'ì¼ì •ì˜', 'ì§€ì›ê¸ˆ', 'ì›ê³ ë£Œ'
}

# OCR ìš”ì²­ìš© ê¸°ë³¸ JSON
request_json = {
    'images': [{'format': 'jpg', 'name': 'demo'}],
    'requestId': str(uuid.uuid4()),
    'version': 'V2',
    'timestamp': int(round(time.time() * 1000))
}
payload = {'message': json.dumps(request_json).encode('UTF-8')}
headers = {'X-OCR-SECRET': secret_key}

# ë””ë ‰í† ë¦¬ ìƒì„±
image_dir = "images"
csv_dir = "../data"
os.makedirs(image_dir, exist_ok=True)
os.makedirs(csv_dir, exist_ok=True)
csv_path = os.path.join(csv_dir, "output.csv")

def get_ocr_data(image_url, cnt):
    img_text = ''
    filename = os.path.join(image_dir, f"{cnt}.jpg")
    img_response = requests.get(image_url)
    if img_response.status_code == 200:
        with open(filename, 'wb') as image_file:
            image_file.write(img_response.content)
    files = [('file', open(filename, 'rb'))]
    response = requests.post(api_url, headers=headers, data=payload, files=files)
    json_data = json.loads(response.text)
    for image in json_data.get('images', []):
        for field in image.get('fields', []):
            img_text += field.get('inferText', '')
    return img_text.strip()

def tag_get_text(tag):
    return tag.get_text().strip() if tag else None

# ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
query = "ë¦¬ë·°"
pageCnt = 380
cnt = 1
desired_cnt = 30

blog_posts = []

while cnt <= desired_cnt:
    try:
        driver.get(f"https://section.blog.naver.com/Search/Post.naver?pageNo={pageCnt}&rangeType=PERIOD&orderBy=recentdate&startDate=2022-03-01&endDate=2022-08-18&keyword={query}")
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        content_list = soup.find('div', class_='area_list_search')
        for a_tag in content_list.find_all('a', 'desc_inner'):
            blog_content, blog_title, ocr_data = "", "", ""
            blog_is_promotional, comments_cnt = 0, 0

            href = a_tag['href']
            driver.get(href)
            time.sleep(2)

            current_html = driver.page_source
            current_soup = BeautifulSoup(current_html, 'html.parser')
            iframe_src = current_soup.find('iframe').get('src')
            if iframe_src.startswith('/'):
                iframe_src = 'https://blog.naver.com' + iframe_src
            driver.get(iframe_src)
            time.sleep(2)

            iframe_html = driver.page_source
            iframe_soup = BeautifulSoup(iframe_html, 'html.parser')

            title = iframe_soup.find('h3', class_='se_textarea')
            content = iframe_soup.select('span[class^="se-fs-"]')
            date = tag_get_text(iframe_soup.find('span', class_='se_publishDate pcol2'))
            writer = tag_get_text(iframe_soup.find('a', class_='link pcol2'))
            images = iframe_soup.select('img[class$="egjs-visible"]')
            empathy_cnt = tag_get_text(iframe_soup.find('em', class_='u_cnt _count'))
            writer_review_str = tag_get_text(iframe_soup.find('h4', class_='category_title pcol2'))
            comments_cnt = tag_get_text(iframe_soup.find('em', class_='_commentCount'))

            writer_reviews_cnt = 0
            if writer_review_str:
                writer_reviews = re.findall(r'\d+', writer_review_str)
                writer_reviews_cnt = int(writer_reviews[0]) if writer_reviews else 0

            blog_title = title.get_text() if title else (content[0].get_text() if content else "")
            for tag in content:
                blog_content += tag.get_text()
            blog_content = blog_content.replace('\u200b', '').replace(' ', '')

            if images:
                image_url = images[-1]['src']
                ocr_data = get_ocr_data(image_url, cnt)
            else:
                ocr_data = ""

            combined_text = blog_content + blog_title + ocr_data
            for promo_word in promotional_text_set:
                if promo_word in combined_text:
                    blog_is_promotional = 1
                    break

            blog_posts.append({
                'cnt': cnt,
                'writer': writer,
                'date': date,
                'url': href.strip(),
                'title': blog_title.strip(),
                'content': blog_content,
                'ocr_data': ocr_data,
                'comments_cnt': comments_cnt,
                'empathy_cnt': empathy_cnt,
                'writer_reviews_cnt': writer_reviews_cnt,
                'blog_is_promotional': blog_is_promotional
            })

            if cnt % 500 == 0:
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as file:
                    fieldnames = ['cnt','writer','date','url','title','content','ocr_data','comments_cnt','empathy_cnt','writer_reviews_cnt','blog_is_promotional']
                    writer = csv.DictWriter(file, fieldnames=fieldnames)
                    writer.writeheader()
                    for item in blog_posts:
                        writer.writerow(item)
                print(f"ğŸ”„ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ - {cnt}ê°œ")

            cnt += 1
            if cnt > desired_cnt:
                break
    except Exception as e:
        print("ë°œìƒí•œ ì˜¤ë¥˜:", e, '\në‹¤ìŒ ë¦¬ë·°ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.')
    pageCnt += 1
    print('ì„±ê³µ', '  pageCnt : ', pageCnt, '   href : ', href)

# CSV ì €ì¥
with open(csv_path, 'w', newline='', encoding='utf-8-sig') as file:
    fieldnames = ['cnt','writer','date','url','title','content','ocr_data','comments_cnt','empathy_cnt','writer_reviews_cnt','blog_is_promotional']
    writer = csv.DictWriter(file, fieldnames=fieldnames)
    writer.writeheader()
    for item in blog_posts:
        writer.writerow(item)

driver.quit()